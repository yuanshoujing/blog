---
title: 大语言模型及 RLHF 的前世今生
tags:
---

ChatGPT 发布以来，大语言模型已经成为大家关注的焦点，并且几乎每周都有新的模型发布。本文尝试带您完整的回顾一下大语言模型的发展历程，从最初最基本的想法，到它最近达到的阶段。涉及：

- 语言模型的学习过程是什么样的？
- RLHF，即基于人类反馈的强化学习究竟是怎么回事儿？如何让语言模型与人类的思考结果对齐？
- 是什么让这些模型变得危险或不符合人类的意图？

我们将从头开始探索上述问题及其它相关问题，并且假定您不具备任何有关 AI 和机器学习的知识。

## 语言智能

伴随 ChatGPT 的广泛传播和采用，现在很多人已经将会话式 AI 变成其日常生活的一部分。本质上，ChatGPT 属于一种被称为大语言模型的 AI 系统，此类系统可以出色的执行各种涉及自然语言分析的任务。

在过去的几个月里，与这项相对较新的技术互动的人数出现了爆炸式的增长。ChatGPT 在发布后不久，就迅速拥有了超过 1 亿独立用户，这是互联网历史上所有服务中被采用速度最快的一次。

![](/images/llm0.png)

与此同时，如何降低这些 AI 模型的风险以及如何不被滥用，如何减少错误或涉嫌剽窃的信息、无意的冒犯或歧视性内容，如何解决语言模型生成机制造成的事实性缺乏等等问题，也日益成为所有提供大型语言模型服务的公司的主要关注点，上述问题的任何一项，最终可能都会损害公众对这项新技术实际潜力的信任。

因此，目前的 AI 领域，对控制性、操纵性和灵活性的要求极高，RLHF 可能是当前最流行的方法。我们将详尽地说明这种方法背后的关键思想是什么，以及 RLHF 对语言模型的确切作用。

让我们先来回顾一下有关语言模型的基本思想，它们是如何训练的，以及它们是如何实际工作的。

## 语言计算

语言和交流的过程可以简化为计算吗?

语言模型(LMs)是一类明确定制的概率模型，用于识别和学习自然语言中的统计模式。语言模型的主要功能是计算给定输入句子中单词成功的概率。

![](/images/llm1.png)

语言模型可以根据它在训练中学习到的统计模式，预测最可能跟随这个短语的单词(或单词)。在图中，语言模型可能估计有 91%的概率，蓝色这个词遵循天空颜色的单词序列。

这些模型是如何训练的呢?核心过程是一种被称为自监督学习的通用技术，这种学习范式利用数据本身的固有结构来生成用于训练的标签。

在自然语言处理的背景下，自监督学习使模型能够从未注释的文本中学习，而不是依赖于相对稀缺且通常昂贵的人工标记数据。

在训练过程中，向 LM 提供大量文本语料库(数据集)，并负责预测句子中的下一个单词。在实践中，这通常是通过随机截断输入句子的最后一部分并训练模型来填充缺失的单词来实现的。随着模型在大量示例中迭代，它学会识别和内化各种语言模式、规则以及单词和概念之间的关系。可以说，通过这个过程，模型创建了语言的内部表示。

![](/images/llm2.png)

在训练过程中，从语料库中提取文本序列并截断。语言模型计算缺失词的概率，然后通过基于梯度下降的优化机制稍微调整并反馈给模型以匹配基本事实。在整个文本语料库上重复这个过程。

这个训练过程的结果是一个预训练的语言模型。通过接触不同的语言模式，该模型为理解自然语言和生成上下文适当和连贯的文本奠定了基础。有些人把这样的预训练模型称为基础模型。
